{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1_309833023.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuCYJSSDFukq"
      },
      "source": [
        "# Lab 1 Sample Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0BmuW9dcCId"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\" Sigmoid function.\n",
        "    This function accepts any shape of np.ndarray object as input and perform sigmoid operation.\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def der_sigmoid(y):\n",
        "    \"\"\" First derivative of Sigmoid function.\n",
        "    The input to this function should be the value that output from sigmoid function.\n",
        "    \"\"\"\n",
        "    return y * (1 - y)\n",
        "\n",
        "\n",
        "class GenData:\n",
        "    @staticmethod\n",
        "    def _gen_linear(n=100):\n",
        "        \"\"\" Data generation (Linear)\n",
        "\n",
        "        Args:\n",
        "            n (int):    the number of data points generated in total.\n",
        "\n",
        "        Returns:\n",
        "            data (np.ndarray, np.float):    the generated data with shape (n, 2). Each row represents\n",
        "                a data point in 2d space.\n",
        "            labels (np.ndarray, np.int):    the labels that correspond to the data with shape (n, 1).\n",
        "                Each row represents a corresponding label (0 or 1).\n",
        "        \"\"\"\n",
        "        data = np.random.uniform(0, 1, (n, 2))\n",
        "\n",
        "        inputs = []\n",
        "        labels = []\n",
        "\n",
        "        for point in data:\n",
        "            inputs.append([point[0], point[1]])\n",
        "\n",
        "            if point[0] > point[1]:\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)\n",
        "\n",
        "        return np.array(inputs), np.array(labels).reshape((-1, 1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_xor(n=100):\n",
        "        \"\"\" Data generation (XOR)\n",
        "\n",
        "        Args:\n",
        "            n (int):    the number of data points generated in total.\n",
        "\n",
        "        Returns:\n",
        "            data (np.ndarray, np.float):    the generated data with shape (n, 2). Each row represents\n",
        "                a data point in 2d space.\n",
        "            labels (np.ndarray, np.int):    the labels that correspond to the data with shape (n, 1).\n",
        "                Each row represents a corresponding label (0 or 1).\n",
        "        \"\"\"\n",
        "        data_x = np.linspace(0, 1, n // 2)\n",
        "\n",
        "        inputs = []\n",
        "        labels = []\n",
        "\n",
        "        for x in data_x:\n",
        "            inputs.append([x, x])\n",
        "            labels.append(0)\n",
        "\n",
        "            if x == 1 - x:\n",
        "                continue\n",
        "\n",
        "            inputs.append([x, 1 - x])\n",
        "            labels.append(1)\n",
        "\n",
        "        return np.array(inputs), np.array(labels).reshape((-1, 1))\n",
        "\n",
        "    @staticmethod\n",
        "    def fetch_data(mode, n):\n",
        "        \"\"\" Data gather interface\n",
        "\n",
        "        Args:\n",
        "            mode (str): 'Linear' or 'XOR', indicate which generator is used.\n",
        "            n (int):    the number of data points generated in total.\n",
        "        \"\"\"\n",
        "        assert mode == 'Linear' or mode == 'XOR'\n",
        "\n",
        "        data_gen_func = {\n",
        "            'Linear': GenData._gen_linear,\n",
        "            'XOR': GenData._gen_xor\n",
        "        }[mode]\n",
        "\n",
        "        return data_gen_func(n)\n",
        "\n",
        "\n",
        "class SimpleNet:\n",
        "    def __init__(self, num_step=2000, print_interval=100):\n",
        "        \"\"\" A hand-crafted implementation of simple network.\n",
        "\n",
        "        Args:\n",
        "            num_step (optional):    the total number of training steps.\n",
        "            print_interval (optional):  the number of steps between each reported number.\n",
        "        \"\"\"\n",
        "        self.num_step = num_step\n",
        "        self.print_interval = print_interval\n",
        "\n",
        "        # Model parameters initialization\n",
        "        # hidden layer 1: 100 nodes\n",
        "        # hidden layer 2: 10 nodes\n",
        "        # Please initiate your network parameters here.\n",
        "        # 初始化各項係數\n",
        "        num_nn_input = 2\n",
        "        num_nn_output = 1\n",
        "        layer1_hidden_size = 100\n",
        "        layer2_hidden_size = 10\n",
        "        \n",
        "        # 根據I/O和神經元個數對weight進行隨機取值\n",
        "        self.w1 = np.random.randn(num_nn_input,layer1_hidden_size)\n",
        "        self.w2 = np.random.randn(layer1_hidden_size,layer2_hidden_size)\n",
        "        self.w3 = np.random.randn(layer2_hidden_size,num_nn_output)\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_result(data, gt_y, pred_y):\n",
        "        \"\"\" Data visualization with ground truth and predicted data comparison. There are two plots\n",
        "        for them and each of them use different colors to differentiate the data with different labels.\n",
        "\n",
        "        Args:\n",
        "            data:   the input data\n",
        "            gt_y:   ground truth to the data\n",
        "            pred_y: predicted results to the data\n",
        "        \"\"\"\n",
        "        assert data.shape[0] == gt_y.shape[0]\n",
        "        assert data.shape[0] == pred_y.shape[0]\n",
        "\n",
        "        plt.figure()\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title('Ground Truth', fontsize=18)\n",
        "\n",
        "        for idx in range(data.shape[0]):\n",
        "            if gt_y[idx] == 0:\n",
        "                plt.plot(data[idx][0], data[idx][1], 'ro')\n",
        "            else:\n",
        "                plt.plot(data[idx][0], data[idx][1], 'bo')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title('Prediction', fontsize=18)\n",
        "\n",
        "        for idx in range(data.shape[0]):\n",
        "            if pred_y[idx] == 0:\n",
        "                plt.plot(data[idx][0], data[idx][1], 'ro')\n",
        "            else:\n",
        "                plt.plot(data[idx][0], data[idx][1], 'bo')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\" Implementation of the forward pass.\n",
        "        It should accepts the inputs and passing them through the network and return results.\n",
        "        \"\"\"\n",
        "        \n",
        "        \"\"\" FILL IN HERE \"\"\"\n",
        "        # Forward為input經過weight傳過sigmold成為下一層的input，一層一層傳至最後一層輸出output\n",
        "        self.first_forward_gradient = inputs \n",
        "        y1 = sigmoid(inputs @ self.w1)\n",
        "        self.y1 = y1 \n",
        "\n",
        "        self.second_forward_gradient = y1\n",
        "        y2 = sigmoid(y1 @ self.w2)\n",
        "        self.y2 = y2\n",
        "\n",
        "        self.third_forward_gradient = y2 \n",
        "        y3 = sigmoid(y2 @ self.w3)\n",
        "        self.y3 = y3\n",
        "        return y3.T\n",
        "\n",
        "    def backward(self):\n",
        "        \"\"\" Implementation of the backward pass.\n",
        "        It should utilize the saved loss to compute gradients and update the network all the way to the front.\n",
        "        \"\"\"\n",
        "        learning_rate = 1e-2\n",
        "\n",
        "        \"\"\" FILL IN HERE \"\"\"\n",
        "        # Backward則為output透過sigmoid一次微分與權重轉置計算出error依序傳至前一層作為輸入\n",
        "        self.third_backward_gradient = der_sigmoid(self.y3) * der_sigmoid(self.error)\n",
        "        third_error = (self.third_backward_gradient @ self.w3.T)\n",
        "        self.second_backward_gradient = der_sigmoid(self.y2) * third_error\n",
        "        second_error = (self.second_backward_gradient @ self.w2.T)\n",
        "        self.first_backward_gradient = der_sigmoid(self.y1) * second_error\n",
        "        \n",
        "    def gradient_calculate(self):\n",
        "        # Total_Gradient為Forward+backward\n",
        "        self.first_total_gradient = (self.first_forward_gradient.T @ self.first_backward_gradient)\n",
        "        self.second_total_gradient = (self.second_forward_gradient.T @ self.second_backward_gradient)\n",
        "        self.third_total_gradient = (self.third_forward_gradient.T @ self.third_backward_gradient)\n",
        "\n",
        "    def weight_update(self, learning_rate):\n",
        "        # 對權重進行更新\n",
        "        self.w1 = (self.w1 - learning_rate * self.first_total_gradient)\n",
        "        self.w2 = (self.w2 - learning_rate * self.second_total_gradient)\n",
        "        self.w3 = (self.w3 - learning_rate * self.third_total_gradient)\n",
        "\n",
        "    def train(self, inputs, labels):\n",
        "        \"\"\" The training routine that runs and update the model.\n",
        "\n",
        "        Args:\n",
        "            inputs: the training (and testing) data used in the model.\n",
        "            labels: the ground truth of correspond to input data.\n",
        "        \"\"\"\n",
        "        # make sure that the amount of data and label is match\n",
        "        assert inputs.shape[0] == labels.shape[0]\n",
        "\n",
        "        n = inputs.shape[0]\n",
        "\n",
        "        for epochs in range(self.num_step):\n",
        "            for idx in range(n):\n",
        "                # operation in each training step:\n",
        "                #   1. forward passing\n",
        "                #   2. compute loss\n",
        "                #   3. propagate gradient backward to the front\n",
        "                \"\"\" apply your backward function: \"\"\"\n",
        "                \"\"\" FILL IN HERE \"\"\"\n",
        "                self.output = self.forward(inputs[idx:idx+1, :])\n",
        "                self.error = (self.output - labels[idx:idx+1, :])\n",
        "                self.backward()\n",
        "                self.gradient_calculate()\n",
        "                self.weight_update(1e-2)\n",
        "\n",
        "\n",
        "            if epochs % self.print_interval == 0:\n",
        "                print('Epochs {}: '.format(epochs))\n",
        "                self.test(inputs, labels)\n",
        "\n",
        "        print('Training finished')\n",
        "        self.test(inputs, labels)\n",
        "\n",
        "    def test(self, inputs, labels):\n",
        "        \"\"\" The testing routine that run forward pass and report the accuracy.\n",
        "\n",
        "        Args:\n",
        "            inputs: the testing data. One or several data samples are both okay.\n",
        "                The shape is expected to be [BatchSize, 2].\n",
        "            labels: the ground truth correspond to the inputs.\n",
        "        \"\"\"\n",
        "        n = inputs.shape[0]\n",
        "\n",
        "        error = 0.0\n",
        "        mse = 0.0\n",
        "        for idx in range(n):\n",
        "            result = self.forward(inputs[idx:idx+1, :])\n",
        "            error += abs(result - labels[idx:idx+1, :])\n",
        "            mse  += (abs(result - labels[idx:idx+1, :])**2)\n",
        "        error /= n\n",
        "        mse  /= n\n",
        "        \n",
        "        print('accuracy: %.2f' % ((1 - error)*100) + '%')\n",
        "        print('')\n",
        "        print('loss: %.5f' % mse)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK3VNavIFpa8"
      },
      "source": [
        "### Run \"Linear\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urzfLhyhET7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6d03005-a4b8-436f-db04-1849cc933583"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    \"\"\" Customize your own code if needed \"\"\"\n",
        "\n",
        "    data, label = GenData.fetch_data('Linear', 100)\n",
        "\n",
        "    net = SimpleNet(1000, 50)\n",
        "    net.train(data, label)\n",
        "\n",
        "    pred_result = np.round(net.forward(data))\n",
        "    SimpleNet.plot_result(data, label, pred_result.T)\n",
        "\n",
        "    \"\"\" FILL IN HERE \"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs 0: \n",
            "accuracy: 50.12%\n",
            "\n",
            "loss: 0.34837\n",
            "\n",
            "Epochs 50: \n",
            "accuracy: 50.90%\n",
            "\n",
            "loss: 0.38423\n",
            "\n",
            "Epochs 100: \n",
            "accuracy: 51.17%\n",
            "\n",
            "loss: 0.39162\n",
            "\n",
            "Epochs 150: \n",
            "accuracy: 51.49%\n",
            "\n",
            "loss: 0.38793\n",
            "\n",
            "Epochs 200: \n",
            "accuracy: 52.00%\n",
            "\n",
            "loss: 0.37296\n",
            "\n",
            "Epochs 250: \n",
            "accuracy: 52.60%\n",
            "\n",
            "loss: 0.35301\n",
            "\n",
            "Epochs 300: \n",
            "accuracy: 53.36%\n",
            "\n",
            "loss: 0.33122\n",
            "\n",
            "Epochs 350: \n",
            "accuracy: 54.63%\n",
            "\n",
            "loss: 0.29920\n",
            "\n",
            "Epochs 400: \n",
            "accuracy: 57.01%\n",
            "\n",
            "loss: 0.24995\n",
            "\n",
            "Epochs 450: \n",
            "accuracy: 61.01%\n",
            "\n",
            "loss: 0.19056\n",
            "\n",
            "Epochs 500: \n",
            "accuracy: 66.03%\n",
            "\n",
            "loss: 0.14052\n",
            "\n",
            "Epochs 550: \n",
            "accuracy: 71.95%\n",
            "\n",
            "loss: 0.10001\n",
            "\n",
            "Epochs 600: \n",
            "accuracy: 76.94%\n",
            "\n",
            "loss: 0.07592\n",
            "\n",
            "Epochs 650: \n",
            "accuracy: 79.69%\n",
            "\n",
            "loss: 0.06353\n",
            "\n",
            "Epochs 700: \n",
            "accuracy: 81.66%\n",
            "\n",
            "loss: 0.05539\n",
            "\n",
            "Epochs 750: \n",
            "accuracy: 83.19%\n",
            "\n",
            "loss: 0.04957\n",
            "\n",
            "Epochs 800: \n",
            "accuracy: 84.43%\n",
            "\n",
            "loss: 0.04513\n",
            "\n",
            "Epochs 850: \n",
            "accuracy: 85.45%\n",
            "\n",
            "loss: 0.04159\n",
            "\n",
            "Epochs 900: \n",
            "accuracy: 86.32%\n",
            "\n",
            "loss: 0.03867\n",
            "\n",
            "Epochs 950: \n",
            "accuracy: 87.07%\n",
            "\n",
            "loss: 0.03620\n",
            "\n",
            "Training finished\n",
            "accuracy: 87.70%\n",
            "\n",
            "loss: 0.03413\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJHxIo2yFeG8"
      },
      "source": [
        "### Run \"XOR\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzEKq9L5Ffu3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b770ef23-3038-4c20-e2a9-15e361c92697"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    \"\"\" Customize your own code if needed \"\"\"\n",
        "    \n",
        "    data, label = GenData.fetch_data('XOR', 100)\n",
        "\n",
        "    net = SimpleNet(5000, 50)\n",
        "    net.train(data, label)\n",
        "\n",
        "    pred_result = np.round(net.forward(data))\n",
        "    SimpleNet.plot_result(data, label, pred_result.T)\n",
        "\n",
        "    \"\"\" FILL IN HERE \"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs 0: \n",
            "accuracy: 49.75%\n",
            "\n",
            "loss: 0.41775\n",
            "\n",
            "Epochs 50: \n",
            "accuracy: 49.85%\n",
            "\n",
            "loss: 0.43392\n",
            "\n",
            "Epochs 100: \n",
            "accuracy: 49.90%\n",
            "\n",
            "loss: 0.44136\n",
            "\n",
            "Epochs 150: \n",
            "accuracy: 49.93%\n",
            "\n",
            "loss: 0.44580\n",
            "\n",
            "Epochs 200: \n",
            "accuracy: 49.95%\n",
            "\n",
            "loss: 0.44876\n",
            "\n",
            "Epochs 250: \n",
            "accuracy: 49.97%\n",
            "\n",
            "loss: 0.45086\n",
            "\n",
            "Epochs 300: \n",
            "accuracy: 49.99%\n",
            "\n",
            "loss: 0.45238\n",
            "\n",
            "Epochs 350: \n",
            "accuracy: 50.01%\n",
            "\n",
            "loss: 0.45348\n",
            "\n",
            "Epochs 400: \n",
            "accuracy: 50.02%\n",
            "\n",
            "loss: 0.45427\n",
            "\n",
            "Epochs 450: \n",
            "accuracy: 50.03%\n",
            "\n",
            "loss: 0.45478\n",
            "\n",
            "Epochs 500: \n",
            "accuracy: 50.05%\n",
            "\n",
            "loss: 0.45506\n",
            "\n",
            "Epochs 550: \n",
            "accuracy: 50.06%\n",
            "\n",
            "loss: 0.45510\n",
            "\n",
            "Epochs 600: \n",
            "accuracy: 50.08%\n",
            "\n",
            "loss: 0.45493\n",
            "\n",
            "Epochs 650: \n",
            "accuracy: 50.09%\n",
            "\n",
            "loss: 0.45450\n",
            "\n",
            "Epochs 700: \n",
            "accuracy: 50.11%\n",
            "\n",
            "loss: 0.45380\n",
            "\n",
            "Epochs 750: \n",
            "accuracy: 50.14%\n",
            "\n",
            "loss: 0.45274\n",
            "\n",
            "Epochs 800: \n",
            "accuracy: 50.17%\n",
            "\n",
            "loss: 0.45124\n",
            "\n",
            "Epochs 850: \n",
            "accuracy: 50.20%\n",
            "\n",
            "loss: 0.44911\n",
            "\n",
            "Epochs 900: \n",
            "accuracy: 50.25%\n",
            "\n",
            "loss: 0.44604\n",
            "\n",
            "Epochs 950: \n",
            "accuracy: 50.32%\n",
            "\n",
            "loss: 0.44141\n",
            "\n",
            "Epochs 1000: \n",
            "accuracy: 50.43%\n",
            "\n",
            "loss: 0.43391\n",
            "\n",
            "Epochs 1050: \n",
            "accuracy: 50.66%\n",
            "\n",
            "loss: 0.42018\n",
            "\n",
            "Epochs 1100: \n",
            "accuracy: 51.27%\n",
            "\n",
            "loss: 0.38996\n",
            "\n",
            "Epochs 1150: \n",
            "accuracy: 53.91%\n",
            "\n",
            "loss: 0.32434\n",
            "\n",
            "Epochs 1200: \n",
            "accuracy: 55.92%\n",
            "\n",
            "loss: 0.31264\n",
            "\n",
            "Epochs 1250: \n",
            "accuracy: 57.49%\n",
            "\n",
            "loss: 0.30663\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}